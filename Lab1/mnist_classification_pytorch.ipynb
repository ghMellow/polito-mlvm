{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Classification"
      ],
      "metadata": {
        "id": "3iBLIGYhsQPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import packages**"
      ],
      "metadata": {
        "id": "TyHNIz6QsURr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0xm3t7q504v8"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a fully connected Neural Network\n",
        "We define a very simple fully connected neural network. It is a subclass of torch.nn.Module. <br>\n",
        "When extending torch.nn.Module we need to define two methods:\n",
        "- `__init__` method:\n",
        "it is the constructor of the class and is called only once, when instantiating the neural network. It initializes the network's architecture by initializing all network layers and other components. It is where you define the structure of the network, such as layers, activation functions, and any other components required for computation.\n",
        "-`forward` method\n",
        "is called when you pass input data through the network. The forward method specifies the sequence of operations that are applied to the input data. It describes how the input data flow through the various layers to produce the final output."
      ],
      "metadata": {
        "id": "Pb5ErZdMsfzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define neural network\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.lin1 = nn.Linear(28*28, 512)\n",
        "        self.act1 = nn.ReLU()\n",
        "\n",
        "        self.lin2 = nn.Linear(512, 512)\n",
        "        self.act2 = nn.ReLU()\n",
        "\n",
        "        self.output_layer = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)  # (batch_size, 28, 28) => (batch_size, 28*28)\n",
        "\n",
        "        # first layer (input is x, output is x1)\n",
        "        x1 = self.lin1(x)\n",
        "        x1 = self.act1(x1)\n",
        "\n",
        "        # second layer (input is x1, output is x2)\n",
        "        x2 = self.lin2(x1)\n",
        "        x2 = self.act2(x2)\n",
        "\n",
        "        # third/output layer (input is x2, output is logits)\n",
        "        logits = self.output_layer(x2)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "YXxGAM0H35lj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "qhJqY-ZJQaHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# preprocessing to apply on each data sample:\n",
        "# 1) convert to tensor\n",
        "# 2) normalize images\n",
        "transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.1307,), std=(0.3081,))  # Normalize a tensor image with mean and standard deviation.\n",
        "        ])\n",
        "\n",
        "# train dataset\n",
        "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "print(f\"MNIST train dataset - num samples: {len(train_dataset)}\")\n",
        "\n",
        "# test dataset\n",
        "test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
        "print(f\"MNIST test dataset - num samples: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1bZT80E4gdY",
        "outputId": "ca95e117-f8c5-4ed8-d78b-fd5e210fed23"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 219574174.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 62473282.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 44647458.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 21285507.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "MNIST train dataset - num samples: 60000\n",
            "MNIST test dataset - num samples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot one sample from dataset"
      ],
      "metadata": {
        "id": "bHPV6AlpCemt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_dataset[100]"
      ],
      "metadata": {
        "id": "-plmwVVLH6li"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qct8Yib_IKo6",
        "outputId": "13fd26c7-9c5f-48d1-f2c0-0a48bdce8f89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHIdA_3oITeR",
        "outputId": "175aa773-53fc-46aa-957c-ac5809928756"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset returns one sample at a time\n",
        "# In our case one sample corresponds to a Tuple: (Image, Target Label)\n",
        "# Image is a tensor with shape [1, 28, 28]\n",
        "# Label is an integer representing the class of the image\n",
        "\n",
        "print(type(train_dataset[100]))\n",
        "print(len(train_dataset[100]))\n",
        "\n",
        "image, label = train_dataset[100]\n",
        "print(\"image: \", image.shape, type(image))\n",
        "print(\"label: \", label, type(label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWOVzrKN56Id",
        "outputId": "f01025e8-c9ad-47b5-ce36-a63ec4cf71ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tuple'>\n",
            "2\n",
            "image:  torch.Size([1, 28, 28]) <class 'torch.Tensor'>\n",
            "label:  5 <class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VglQ4o-OI2PM",
        "outputId": "ea3a617b-337b-45ea-fbaf-6f36661c56dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eYKl3xNI5NH",
        "outputId": "30bb7cbd-607a-419a-e1dd-6323618739b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = image.view(28,28)\n",
        "image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1eqKWkgI9GR",
        "outputId": "c1a071d4-d2e6-4db2-d6b3-7ac8cd936996"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot one sample normalized\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image.numpy())  # numpy array 28x28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "_JAtWFQkR_0Y",
        "outputId": "f1da70ee-c0b9-4ae5-ee5c-96b70421da69"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7db577bf7400>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader\n",
        "Dataloader reads from the dataset and returns batches of data. We need to specify at least:\n",
        "- `dataset`: torch.utils.data.Dataset object from which the DataLoader fetch data\n",
        "- `batch_size`: number of sample in a batch, e.g. 128, choose the maximum that the GPU can fit\n",
        "\n",
        "Other parameters are:\n",
        "- `shuffle`: boolean, whether we want to shuffle the data samples\n",
        "- `drop_last`: boolean, whether the last batch, which may have fewer samples than the specified batch size, should be included or dropped\n",
        "\n"
      ],
      "metadata": {
        "id": "iSqvt0wTYB9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128  # we define here the batch size: number of samples processed before the model is updated\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True) #, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False) # , drop_last=False)\n",
        "print(f\"batch size: {batch_size}\")"
      ],
      "metadata": {
        "id": "5Rjxpi3J42oR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2714e21-c703-488f-f957-4a43aa0e8729"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "kP8VtriNSMFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for training\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()  # model to train mode\n",
        "\n",
        "    # ITERATE DATALOADER: train_loader\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        #  SINGLE OPTIMIZATION STEP IS PERFORMED ON A BATCH!\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = F.cross_entropy(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "# test\n",
        "# function for evaluation\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()  # model to eval\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # ITERATE DATALOADER: test_loader\n",
        "    for data, target in test_loader:\n",
        "        batch_size = data.shape[0]\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "\n",
        "        # sanity check\n",
        "        pred = pred.view(batch_size)  # [bs,]\n",
        "        target = target.view(batch_size)  # [bs,]\n",
        "\n",
        "        # compute prediction ok\n",
        "        batch_pred_ok = pred.eq(target).sum().item()\n",
        "        correct += batch_pred_ok\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    num_samples = len(test_loader.dataset)\n",
        "    test_accuracy = correct / num_samples\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "3HlkzQx64GZW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')  # use gpu, is equivalent to .cuda()\n",
        "\n",
        "# training hyperparameters\n",
        "lr = 0.01\n",
        "num_epochs = 5\n",
        "print(f\"lr: {lr}\")\n",
        "print(f\"batch size: {batch_size}\")\n",
        "print(f\"Num. optimization steps per-epoch: {int(len(train_dataset)/batch_size)}\")\n",
        "\n",
        "#########\n",
        "# MODEL #\n",
        "#########\n",
        "model = NeuralNetwork(num_classes=10)\n",
        "model = model.to(device)\n",
        "\n",
        "#############\n",
        "# OPTIMIZER #\n",
        "#############\n",
        "parameters_to_optimize = model.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D609MxPV7gvZ",
        "outputId": "8a71e5e8-6063-4ff2-9176-db63e10ffc4b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr: 0.01\n",
            "batch size: 128\n",
            "Num. optimization steps per-epoch: 468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  train(model, device, train_loader, optimizer, epoch)\n",
        "  test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ7HhNC7S8Ny",
        "outputId": "e54b213f-fdfc-4004-a875-7d0f2540761e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304910\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.496038\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.503941\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.367268\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.298520\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.280180\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.162909\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.320560\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.268460\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.163087\n",
            "\n",
            "Test set: Average loss: 0.1778, Accuracy: 9465/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.309839\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.202926\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.139450\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.116399\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.203200\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.136178\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.149274\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.237649\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.043020\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.087739\n",
            "\n",
            "Test set: Average loss: 0.1074, Accuracy: 9660/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.085218\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.111103\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.128741\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.050657\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.040385\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.142044\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.041928\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.105052\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.038681\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.060147\n",
            "\n",
            "Test set: Average loss: 0.0863, Accuracy: 9724/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.098391\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.059577\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.051766\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.092834\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.043080\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.038009\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.078497\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.122202\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.157083\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.110728\n",
            "\n",
            "Test set: Average loss: 0.0746, Accuracy: 9758/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.041813\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.049383\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.052827\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.037612\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.070825\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.069886\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.023421\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.084906\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.082661\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.037020\n",
            "\n",
            "Test set: Average loss: 0.0687, Accuracy: 9775/10000 (98%)\n",
            "\n",
            "CPU times: user 1min 14s, sys: 432 ms, total: 1min 15s\n",
            "Wall time: 1min 21s\n"
          ]
        }
      ]
    }
  ]
}